# æ•°æ®å½’ä¸€åŒ–å’Œç±»åˆ«å˜é‡å¤„ç†åˆ†æä¸ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“Š å½“å‰å®ç°åˆ†æ

### 1. ç°æœ‰é€»è¾‘æ¦‚è§ˆ

æ‚¨çš„ä»£ç åœ¨ä»¥ä¸‹å‡ ä¸ªåœ°æ–¹å¤„ç†å½’ä¸€åŒ–å’Œç±»åˆ«å˜é‡ï¼š

#### 1.1 è®­ç»ƒé˜¶æ®µ (`train` æ–¹æ³•, è¡Œ 1432-1497)
```python
# å½’ä¸€åŒ–é€»è¾‘
if self.args.scale:
    scaler_features = MinMaxScaler()
    numeric_features = [col for col in X_train_df.columns if col not in categorical_features]
    if not X_train_df[numeric_features].empty:
        X_train_df.loc[:, numeric_features] = scaler_features.fit_transform(X_train_df[numeric_features])
    
    # ç±»åˆ«ç‰¹å¾ç¼–ç 
    for col in categorical_features:
        if col in X_train_df.columns:
            X_train_df.loc[:, col] = X_train_df[col].astype('category').cat.codes
```

#### 1.2 é¢„æµ‹é˜¶æ®µï¼ˆå¤šä¸ªé¢„æµ‹æ–¹æ³•ä¸­é‡å¤ï¼‰
```python
if scaler_features is not None:
    if self.args.encode_categorical_features:
        categorical_features = [...]
        numeric_features = [col for col in X_test.columns if col not in categorical_features]
        
        X_test_scaled = X_test.copy()
        if numeric_features:
            X_test_scaled.loc[:, numeric_features] = scaler_features.transform(X_test_scaled[numeric_features])
        
        for col in categorical_features:
            X_test_scaled.loc[:, col] = X_test_scaled[col].apply(lambda x: int(x))
```

---

## ğŸ” å­˜åœ¨çš„é—®é¢˜

### é—®é¢˜ 1: ç±»åˆ«ç‰¹å¾å¤„ç†é€»è¾‘æ··ä¹± âš ï¸

**é—®é¢˜æè¿°ï¼š**
```python
# è®­ç»ƒæ—¶
categorical_features = []  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨ï¼
if self.args.encode_categorical_features:
    categorical_features = [f for f in sorted(set(categorical_features), key=categorical_features.index) 
                           if f in X_train_df.columns]
```

**ä¸¥é‡ç¼ºé™·ï¼š**
- `categorical_features` åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
- å³ä½¿ `encode_categorical_features=True`ï¼Œä¹Ÿåªæ˜¯ä»ç©ºåˆ—è¡¨ä¸­ç­›é€‰ï¼Œç»“æœä»ç„¶æ˜¯ç©ºåˆ—è¡¨
- **è¿™æ„å‘³ç€ç±»åˆ«ç‰¹å¾å¤„ç†é€»è¾‘å®Œå…¨å¤±æ•ˆï¼**

**å®é™…å½±å“ï¼š**
- ç±»åˆ«ç‰¹å¾è¢«å½“ä½œæ•°å€¼ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–
- LightGBM æ— æ³•æ­£ç¡®è¯†åˆ«ç±»åˆ«ç‰¹å¾
- æ¨¡å‹æ€§èƒ½å¯èƒ½å—åˆ°ä¸¥é‡å½±å“

---

### é—®é¢˜ 2: ç±»åˆ«ç‰¹å¾ç¼–ç æ–¹å¼ä¸ä¸€è‡´ âš ï¸

**è®­ç»ƒæ—¶ï¼š**
```python
X_train_df.loc[:, col] = X_train_df[col].astype('category').cat.codes
```

**é¢„æµ‹æ—¶ï¼š**
```python
X_test_scaled.loc[:, col] = X_test_scaled[col].apply(lambda x: int(x))
```

**é—®é¢˜ï¼š**
1. **è®­ç»ƒæ—¶**ä½¿ç”¨ `cat.codes`ï¼Œè¿™ä¼šè‡ªåŠ¨ç¼–ç ä¸º 0, 1, 2, ...
2. **é¢„æµ‹æ—¶**ä½¿ç”¨ `int(x)`ï¼Œå‡è®¾å€¼å·²ç»æ˜¯æ•´æ•°

**é£é™©ï¼š**
- å¦‚æœæµ‹è¯•æ•°æ®ä¸­ç±»åˆ«ç‰¹å¾æ˜¯å­—ç¬¦ä¸²ï¼Œ`int(x)` ä¼šæŠ¥é”™
- å³ä½¿æ˜¯æ•°å€¼ï¼Œä¹Ÿå¯èƒ½ä¸è®­ç»ƒæ—¶çš„ç¼–ç ä¸ä¸€è‡´
- **è®­ç»ƒå’Œé¢„æµ‹çš„æ•°æ®åˆ†å¸ƒä¸ä¸€è‡´**

---

### é—®é¢˜ 3: é‡å¤ä»£ç ä¸¥é‡ ğŸ”„

**ç»Ÿè®¡ï¼š**
- å½’ä¸€åŒ–é€»è¾‘åœ¨ 7+ ä¸ªé¢„æµ‹æ–¹æ³•ä¸­é‡å¤
- ç±»åˆ«ç‰¹å¾å¤„ç†åœ¨ 7+ ä¸ªåœ°æ–¹é‡å¤
- ä»£ç å†—ä½™åº¦ > 70%

**åæœï¼š**
- ç»´æŠ¤å›°éš¾
- å®¹æ˜“å‡ºç°ä¸ä¸€è‡´
- ä¿®æ”¹ä¸€å¤„å¿˜è®°ä¿®æ”¹å…¶ä»–åœ°æ–¹

---

### é—®é¢˜ 4: ç¼ºå°‘ç±»åˆ«ç‰¹å¾æ˜ å°„å™¨ ğŸ“

**å½“å‰é—®é¢˜ï¼š**
```python
# è®­ç»ƒæ—¶å¯¹ 'date_type' è¿›è¡Œç¼–ç 
# å‡è®¾å€¼ä¸º: ['å·¥ä½œæ—¥', 'å‘¨æœ«', 'èŠ‚å‡æ—¥']
# cat.codes ç¼–ç ä¸º: [0, 1, 2]

# é¢„æµ‹æ—¶ï¼Œæ–°æ•°æ®ä»æ˜¯ ['å·¥ä½œæ—¥', 'å‘¨æœ«', 'èŠ‚å‡æ—¥']
# ä½†ä»£ç æœŸæœ›æ˜¯ [0, 1, 2]
```

**ç¼ºå¤±ï¼š**
- æ²¡æœ‰ä¿å­˜ç±»åˆ«åˆ°ç¼–ç çš„æ˜ å°„å…³ç³»
- æ— æ³•åœ¨é¢„æµ‹æ—¶æ­£ç¡®åº”ç”¨ç›¸åŒçš„ç¼–ç 

---

### é—®é¢˜ 5: LightGBM ç±»åˆ«ç‰¹å¾ä½¿ç”¨ä¸å½“ ğŸ¯

**å½“å‰é€»è¾‘ï¼š**
```python
model.fit(
    X_train_df,
    Y_train_df,
    categorical_feature=categorical_features,  # ä¼ é€’åˆ—å
    ...
)
```

**é—®é¢˜ï¼š**
- å·²ç»å°†ç±»åˆ«ç‰¹å¾ç¼–ç ä¸ºæ•´æ•°
- åˆå‘Šè¯‰ LightGBM è¿™äº›æ˜¯ç±»åˆ«ç‰¹å¾
- **åŒé‡å¤„ç†ï¼Œè¯­ä¹‰æ··ä¹±**

**LightGBM æœ€ä½³å®è·µï¼š**
- æ–¹å¼1: ä¿æŒåŸå§‹ç±»åˆ«ï¼ˆå­—ç¬¦ä¸²/æ•´æ•°ï¼‰ï¼Œä¼ é€’ `categorical_feature`
- æ–¹å¼2: æ‰‹åŠ¨ç¼–ç ä¸ºæ•´æ•°ï¼Œ**ä¸**ä¼ é€’ `categorical_feature`
- **ä¸è¦æ··ç”¨ï¼**

---

### é—®é¢˜ 6: å½’ä¸€åŒ–èŒƒå›´é€‰æ‹©ä¸å½“ ğŸ“

**å½“å‰ä½¿ç”¨ï¼š** `MinMaxScaler()`

**é—®é¢˜ï¼š**
- æ»åç‰¹å¾çš„å€¼èŒƒå›´ä¸åŸå§‹å€¼ç›¸åŒ
- æ—¶é—´ç‰¹å¾ï¼ˆå°æ—¶ã€æ˜ŸæœŸç­‰ï¼‰æœ‰å›ºå®šèŒƒå›´
- å¤©æ°”ç‰¹å¾ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ç­‰ï¼‰èŒƒå›´ä¸åŒ

**MinMaxScaler çš„ç¼ºé™·ï¼š**
- å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ
- æ–°æ•°æ®å¯èƒ½è¶…å‡ºè®­ç»ƒèŒƒå›´ [0, 1]
- é¢„æµ‹æ—¶å¯èƒ½å‡ºç° <0 æˆ– >1 çš„å€¼

---

## âœ… ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä¿®å¤ç±»åˆ«ç‰¹å¾å¤„ç†é€»è¾‘ï¼ˆå¿…é¡»ï¼‰

#### 1.1 ä¿®æ”¹ `train` æ–¹æ³•

```python
def train(self, X_train, Y_train, categorical_features_input):
    """
    æ¨¡å‹è®­ç»ƒ
    
    Args:
        X_train: è®­ç»ƒç‰¹å¾
        Y_train: è®­ç»ƒç›®æ ‡
        categorical_features_input: ç±»åˆ«ç‰¹å¾åˆ—è¡¨ï¼ˆä»å¤–éƒ¨ä¼ å…¥ï¼‰
    """
    X_train_df = X_train.copy()
    Y_train_df = Y_train.copy()
    
    # ç¡®å®šå®é™…å­˜åœ¨çš„ç±»åˆ«ç‰¹å¾
    categorical_features = [
        f for f in categorical_features_input 
        if f in X_train_df.columns
    ] if self.args.encode_categorical_features else []
    
    # ä¿å­˜ç±»åˆ«ç‰¹å¾ç¼–ç å™¨
    self.category_encoders = {}
    scaler_features = None
    
    if self.args.scale:
        scaler_features = MinMaxScaler()  # æˆ–æ”¹ç”¨ StandardScaler()
        numeric_features = [col for col in X_train_df.columns if col not in categorical_features]
        
        if numeric_features:
            X_train_df.loc[:, numeric_features] = scaler_features.fit_transform(
                X_train_df[numeric_features]
            )
    
    # ç±»åˆ«ç‰¹å¾ç¼–ç ï¼ˆè®­ç»ƒæ—¶ï¼‰
    if self.args.encode_categorical_features and categorical_features:
        for col in categorical_features:
            if col in X_train_df.columns:
                # åˆ›å»ºç¼–ç å™¨å¹¶ä¿å­˜æ˜ å°„
                X_train_df[col] = X_train_df[col].astype('category')
                self.category_encoders[col] = {
                    'categories': X_train_df[col].cat.categories.tolist(),
                    'codes': dict(enumerate(X_train_df[col].cat.categories))
                }
                X_train_df[col] = X_train_df[col].cat.codes
    
    # æ¨¡å‹è®­ç»ƒ
    lgbm_estimator = lgb.LGBMRegressor(**self.model_params)
    
    # æ ¹æ®ç¼–ç ç­–ç•¥å†³å®šæ˜¯å¦ä¼ é€’ categorical_feature
    lgbm_categorical = categorical_features if not self.args.encode_categorical_features else None
    
    if self.args.pred_method in [...]:
        model = lgbm_estimator
        model.fit(
            X_train_df,
            Y_train_df,
            categorical_feature=lgbm_categorical,  # åªåœ¨ä¸ç¼–ç æ—¶ä¼ é€’
            eval_set=[(X_train_df, Y_train_df)],
            eval_metric="mae",
            callbacks=[lgb.early_stopping(self.args.patience, verbose=False)],
        )
    else:
        model = MultiOutputRegressor(estimator=lgbm_estimator)
        model.fit(X_train_df, Y_train_df)
    
    return model, scaler_features
```

#### 1.2 åˆ›å»ºç»Ÿä¸€çš„ç‰¹å¾é¢„å¤„ç†æ–¹æ³•

```python
def preprocess_features(self, X, scaler_features=None, categorical_features=None, is_training=False):
    """
    ç»Ÿä¸€çš„ç‰¹å¾é¢„å¤„ç†æ–¹æ³•
    
    Args:
        X: è¾“å…¥ç‰¹å¾
        scaler_features: å½’ä¸€åŒ–å™¨ï¼ˆé¢„æµ‹æ—¶ä¼ å…¥ï¼‰
        categorical_features: ç±»åˆ«ç‰¹å¾åˆ—è¡¨
        is_training: æ˜¯å¦ä¸ºè®­ç»ƒé˜¶æ®µ
    
    Returns:
        é¢„å¤„ç†åçš„ç‰¹å¾
    """
    X_processed = X.copy()
    
    # ç¡®å®šç±»åˆ«ç‰¹å¾
    if categorical_features is None:
        categorical_features = []
    categorical_features = [f for f in categorical_features if f in X_processed.columns]
    
    # æ•°å€¼ç‰¹å¾å½’ä¸€åŒ–
    if scaler_features is not None:
        numeric_features = [col for col in X_processed.columns if col not in categorical_features]
        
        if numeric_features:
            X_processed.loc[:, numeric_features] = scaler_features.transform(
                X_processed[numeric_features]
            )
    
    # ç±»åˆ«ç‰¹å¾ç¼–ç ï¼ˆé¢„æµ‹æ—¶ï¼‰
    if self.args.encode_categorical_features and categorical_features:
        for col in categorical_features:
            if col in X_processed.columns and col in self.category_encoders:
                encoder_info = self.category_encoders[col]
                
                # ä½¿ç”¨ä¿å­˜çš„æ˜ å°„è¿›è¡Œç¼–ç 
                X_processed[col] = X_processed[col].astype('category')
                X_processed[col] = X_processed[col].cat.set_categories(encoder_info['categories'])
                X_processed[col] = X_processed[col].cat.codes
                
                # å¤„ç†æœªçŸ¥ç±»åˆ«ï¼ˆç¼–ç ä¸º -1ï¼‰
                X_processed[col] = X_processed[col].replace(-1, 0)  # æˆ–å…¶ä»–ç­–ç•¥
    
    return X_processed
```

---

### æ–¹æ¡ˆ 2: æ”¹è¿›å½’ä¸€åŒ–ç­–ç•¥

#### 2.1 ä½¿ç”¨ `StandardScaler` æ›¿ä»£ `MinMaxScaler`

**ä¼˜åŠ¿ï¼š**
- å¯¹å¼‚å¸¸å€¼æ›´é²æ£’
- ä¸å—æ•°æ®èŒƒå›´é™åˆ¶
- é€‚åˆç¥ç»ç½‘ç»œå’Œæ ‘æ¨¡å‹

```python
# åœ¨é…ç½®ä¸­æ·»åŠ é€‰é¡¹
scaler_type = "standard"  # æˆ– "minmax"

# åœ¨ train æ–¹æ³•ä¸­
if self.args.scale:
    if self.args.scaler_type == "standard":
        scaler_features = StandardScaler()
    else:
        scaler_features = MinMaxScaler()
```

#### 2.2 ç‰¹å¾åˆ†ç»„å½’ä¸€åŒ–

```python
def create_feature_groups(self, X_train_df, categorical_features):
    """
    å°†ç‰¹å¾åˆ†ç»„ï¼Œä¸åŒç»„ä½¿ç”¨ä¸åŒçš„å½’ä¸€åŒ–ç­–ç•¥
    """
    feature_groups = {
        'lag_features': [col for col in X_train_df.columns if '_lag_' in col],
        'datetime_features': [col for col in X_train_df.columns if 'datetime_' in col],
        'weather_features': [col for col in X_train_df.columns if col in self.args.weather_features],
        'other_numeric': []
    }
    
    # å…¶ä½™æ•°å€¼ç‰¹å¾
    all_special = (
        feature_groups['lag_features'] + 
        feature_groups['datetime_features'] + 
        feature_groups['weather_features'] + 
        categorical_features
    )
    feature_groups['other_numeric'] = [
        col for col in X_train_df.columns 
        if col not in all_special
    ]
    
    return feature_groups

def train_with_grouped_scaling(self, X_train, Y_train, categorical_features_input):
    """
    ä½¿ç”¨åˆ†ç»„å½’ä¸€åŒ–ç­–ç•¥è®­ç»ƒæ¨¡å‹
    """
    X_train_df = X_train.copy()
    Y_train_df = Y_train.copy()
    
    categorical_features = [
        f for f in categorical_features_input 
        if f in X_train_df.columns
    ] if self.args.encode_categorical_features else []
    
    # åˆ›å»ºç‰¹å¾åˆ†ç»„
    feature_groups = self.create_feature_groups(X_train_df, categorical_features)
    
    # ä¸ºæ¯ç»„ç‰¹å¾åˆ›å»ºç‹¬ç«‹çš„ç¼©æ”¾å™¨
    self.scalers = {}
    
    if self.args.scale:
        for group_name, features in feature_groups.items():
            if features and group_name != 'datetime_features':  # æ—¶é—´ç‰¹å¾é€šå¸¸ä¸éœ€è¦ç¼©æ”¾
                self.scalers[group_name] = StandardScaler()
                X_train_df.loc[:, features] = self.scalers[group_name].fit_transform(
                    X_train_df[features]
                )
    
    # ... åç»­è®­ç»ƒé€»è¾‘
```

---

### æ–¹æ¡ˆ 3: LightGBM ç±»åˆ«ç‰¹å¾æœ€ä½³å®è·µ

#### 3.1 æ¨èç­–ç•¥ï¼šè®© LightGBM è‡ªåŠ¨å¤„ç†

```python
def train(self, X_train, Y_train, categorical_features_input):
    """
    ä½¿ç”¨ LightGBM åŸç”Ÿç±»åˆ«ç‰¹å¾æ”¯æŒ
    """
    X_train_df = X_train.copy()
    Y_train_df = Y_train.copy()
    
    # ç¡®å®šç±»åˆ«ç‰¹å¾
    categorical_features = [
        f for f in categorical_features_input 
        if f in X_train_df.columns
    ]
    
    # æ•°å€¼ç‰¹å¾å½’ä¸€åŒ–
    scaler_features = None
    if self.args.scale:
        numeric_features = [col for col in X_train_df.columns if col not in categorical_features]
        if numeric_features:
            scaler_features = StandardScaler()
            X_train_df.loc[:, numeric_features] = scaler_features.fit_transform(
                X_train_df[numeric_features]
            )
    
    # å°†ç±»åˆ«ç‰¹å¾è½¬æ¢ä¸º category ç±»å‹ï¼ˆä¸ç¼–ç ä¸ºæ•´æ•°ï¼‰
    for col in categorical_features:
        X_train_df[col] = X_train_df[col].astype('category')
    
    # è®­ç»ƒæ¨¡å‹
    lgbm_estimator = lgb.LGBMRegressor(**self.model_params)
    
    if self.args.pred_method in [...]:
        model = lgbm_estimator
        model.fit(
            X_train_df,
            Y_train_df,
            categorical_feature=categorical_features,  # ä¼ é€’ç±»åˆ«ç‰¹å¾å
            eval_set=[(X_train_df, Y_train_df)],
            eval_metric="mae",
            callbacks=[lgb.early_stopping(self.args.patience, verbose=False)],
        )
    
    return model, scaler_features
```

**é¢„æµ‹æ—¶ï¼š**
```python
def preprocess_features_for_prediction(self, X, scaler_features, categorical_features):
    """
    é¢„æµ‹æ—¶çš„ç‰¹å¾é¢„å¤„ç†
    """
    X_processed = X.copy()
    
    # æ•°å€¼ç‰¹å¾å½’ä¸€åŒ–
    if scaler_features is not None:
        numeric_features = [col for col in X_processed.columns if col not in categorical_features]
        if numeric_features:
            X_processed.loc[:, numeric_features] = scaler_features.transform(
                X_processed[numeric_features]
            )
    
    # ç±»åˆ«ç‰¹å¾è½¬æ¢ä¸º category ç±»å‹ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    for col in categorical_features:
        if col in X_processed.columns:
            X_processed[col] = X_processed[col].astype('category')
    
    return X_processed
```

---

### æ–¹æ¡ˆ 4: æ·»åŠ æ•°æ®éªŒè¯å’Œæ—¥å¿—

```python
def validate_and_log_features(self, X, stage="training"):
    """
    éªŒè¯å’Œè®°å½•ç‰¹å¾ä¿¡æ¯
    """
    logger.info(f"{self.log_prefix} [{stage}] Feature validation:")
    logger.info(f"{self.log_prefix} Shape: {X.shape}")
    logger.info(f"{self.log_prefix} Columns: {X.columns.tolist()}")
    
    # æ£€æŸ¥æ•°å€¼ç‰¹å¾çš„èŒƒå›´
    numeric_cols = X.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        logger.info(f"{self.log_prefix} Numeric features statistics:")
        logger.info(f"\n{X[numeric_cols].describe()}")
    
    # æ£€æŸ¥ç±»åˆ«ç‰¹å¾
    categorical_cols = X.select_dtypes(include=['category', 'object']).columns
    if len(categorical_cols) > 0:
        logger.info(f"{self.log_prefix} Categorical features:")
        for col in categorical_cols:
            unique_vals = X[col].unique()
            logger.info(f"{self.log_prefix}   {col}: {len(unique_vals)} unique values")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing = X.isnull().sum()
    if missing.sum() > 0:
        logger.warning(f"{self.log_prefix} Missing values detected:")
        logger.warning(f"\n{missing[missing > 0]}")
    
    # æ£€æŸ¥æ— ç©·å€¼
    inf_cols = X.columns[np.isinf(X.select_dtypes(include=[np.number])).any()]
    if len(inf_cols) > 0:
        logger.error(f"{self.log_prefix} Infinite values detected in: {inf_cols.tolist()}")
```

---

## ğŸ“‹ å®æ–½å»ºè®®

### é˜¶æ®µ 1: ç«‹å³ä¿®å¤ï¼ˆå¿…é¡»ï¼‰

1. **ä¿®å¤ç±»åˆ«ç‰¹å¾åˆå§‹åŒ–é€»è¾‘**
   - åœ¨ `train` æ–¹æ³•ä¸­ä¼ å…¥æ­£ç¡®çš„ `categorical_features`
   - å½“å‰ä»£ç å®Œå…¨æ— æ³•å¤„ç†ç±»åˆ«ç‰¹å¾

2. **ç»Ÿä¸€ç¼–ç ç­–ç•¥**
   - è®­ç»ƒå’Œé¢„æµ‹ä½¿ç”¨ç›¸åŒçš„ç¼–ç æ–¹å¼
   - ä¿å­˜ç±»åˆ«ç¼–ç æ˜ å°„

### é˜¶æ®µ 2: é‡æ„ä¼˜åŒ–ï¼ˆæ¨èï¼‰

1. **åˆ›å»ºç»Ÿä¸€çš„é¢„å¤„ç†æ–¹æ³•**
   - å‡å°‘ä»£ç é‡å¤
   - ç¡®ä¿ä¸€è‡´æ€§

2. **æ”¹ç”¨ StandardScaler**
   - æ›´é€‚åˆæ—¶é—´åºåˆ—æ•°æ®
   - å¯¹å¼‚å¸¸å€¼æ›´é²æ£’

3. **ä½¿ç”¨ LightGBM åŸç”Ÿç±»åˆ«ç‰¹å¾æ”¯æŒ**
   - ä¸æ‰‹åŠ¨ç¼–ç 
   - æ€§èƒ½æ›´å¥½

### é˜¶æ®µ 3: é«˜çº§ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

1. **ç‰¹å¾åˆ†ç»„å½’ä¸€åŒ–**
   - ä¸åŒç±»å‹ç‰¹å¾ä½¿ç”¨ä¸åŒç­–ç•¥

2. **æ·»åŠ ç‰¹å¾éªŒè¯**
   - æ—©æœŸå‘ç°æ•°æ®é—®é¢˜

---

## ğŸ¯ æ¨èçš„å®Œæ•´å®ç°

```python
class Model:
    def __init__(self, args):
        self.args = args
        self.scalers = None  # å½’ä¸€åŒ–å™¨
        self.category_info = {}  # ç±»åˆ«ç‰¹å¾ä¿¡æ¯
    
    def _preprocess_features(self, X, categorical_features, is_training=False):
        """
        ç»Ÿä¸€çš„ç‰¹å¾é¢„å¤„ç†
        
        Args:
            X: è¾“å…¥ç‰¹å¾DataFrame
            categorical_features: ç±»åˆ«ç‰¹å¾åˆ—è¡¨
            is_training: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
        
        Returns:
            é¢„å¤„ç†åçš„ç‰¹å¾DataFrame
        """
        X_processed = X.copy()
        
        # 1. ç¡®å®šå®é™…å­˜åœ¨çš„ç±»åˆ«ç‰¹å¾
        actual_categorical = [f for f in categorical_features if f in X_processed.columns]
        
        # 2. æ•°å€¼ç‰¹å¾å½’ä¸€åŒ–
        numeric_features = [col for col in X_processed.columns if col not in actual_categorical]
        
        if self.args.scale and numeric_features:
            if is_training:
                # è®­ç»ƒæ¨¡å¼ï¼šfit_transform
                self.scalers = StandardScaler()
                X_processed.loc[:, numeric_features] = self.scalers.fit_transform(
                    X_processed[numeric_features]
                )
            else:
                # é¢„æµ‹æ¨¡å¼ï¼štransform
                if self.scalers is not None:
                    X_processed.loc[:, numeric_features] = self.scalers.transform(
                        X_processed[numeric_features]
                    )
        
        # 3. ç±»åˆ«ç‰¹å¾å¤„ç†
        for col in actual_categorical:
            if is_training:
                # è®­ç»ƒæ¨¡å¼ï¼šä¿å­˜ç±»åˆ«ä¿¡æ¯
                X_processed[col] = X_processed[col].astype('category')
                self.category_info[col] = X_processed[col].cat.categories.tolist()
            else:
                # é¢„æµ‹æ¨¡å¼ï¼šä½¿ç”¨ä¿å­˜çš„ç±»åˆ«ä¿¡æ¯
                if col in self.category_info:
                    X_processed[col] = pd.Categorical(
                        X_processed[col], 
                        categories=self.category_info[col]
                    )
                else:
                    X_processed[col] = X_processed[col].astype('category')
        
        return X_processed, actual_categorical
    
    def train(self, X_train, Y_train, categorical_features):
        """
        æ¨¡å‹è®­ç»ƒ
        """
        # é¢„å¤„ç†è®­ç»ƒç‰¹å¾
        X_train_processed, actual_categorical = self._preprocess_features(
            X_train, 
            categorical_features, 
            is_training=True
        )
        
        Y_train_df = Y_train.copy()
        
        # æ¨¡å‹è®­ç»ƒ
        lgbm_estimator = lgb.LGBMRegressor(**self.model_params)
        
        if self.args.pred_method in ["univariate-single-multistep-direct-output", ...]:
            model = lgbm_estimator
            model.fit(
                X_train_processed,
                Y_train_df,
                categorical_feature=actual_categorical,
                eval_set=[(X_train_processed, Y_train_df)],
                eval_metric="mae",
                callbacks=[lgb.early_stopping(self.args.patience, verbose=False)],
            )
        else:
            model = MultiOutputRegressor(estimator=lgbm_estimator)
            model.fit(X_train_processed, Y_train_df)
        
        return model
    
    def predict(self, model, X_test, categorical_features):
        """
        æ¨¡å‹é¢„æµ‹
        """
        # é¢„å¤„ç†æµ‹è¯•ç‰¹å¾
        X_test_processed, _ = self._preprocess_features(
            X_test, 
            categorical_features, 
            is_training=False
        )
        
        # é¢„æµ‹
        Y_pred = model.predict(X_test_processed)
        
        return Y_pred
```

---

## âš¡ å¿«é€Ÿä¿®å¤æ–¹æ¡ˆï¼ˆæœ€å°æ”¹åŠ¨ï¼‰

å¦‚æœéœ€è¦æœ€å¿«é€Ÿåº¦ä¿®å¤å½“å‰ä»£ç ï¼Œåªéœ€ï¼š

### æ­¥éª¤ 1: ä¿®æ”¹ `train` æ–¹æ³•ç­¾å

```python
# åŸæ¥
def train(self, X_train, Y_train):

# æ”¹ä¸º
def train(self, X_train, Y_train, categorical_features):
```

### æ­¥éª¤ 2: åˆ é™¤é”™è¯¯çš„åˆå§‹åŒ–

```python
# åˆ é™¤è¿™è¡Œ
# categorical_features = []

# ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
categorical_features = [
    f for f in categorical_features 
    if f in X_train_df.columns
] if self.args.encode_categorical_features else []
```

### æ­¥éª¤ 3: æ›´æ–°æ‰€æœ‰è°ƒç”¨ `train` çš„åœ°æ–¹

```python
# åœ¨ test æ–¹æ³•ä¸­
model, scaler_features = self.train(X_train, Y_train, categorical_features)

# åœ¨ forecast æ–¹æ³•ä¸­
model = self.train(X_train_history, Y_train_history, categorical_features)
```

---

## ğŸ”¬ æµ‹è¯•éªŒè¯

### éªŒè¯æ¸…å•

1. âœ… ç±»åˆ«ç‰¹å¾æ˜¯å¦æ­£ç¡®ä¼ é€’åˆ°æ¨¡å‹
2. âœ… è®­ç»ƒå’Œé¢„æµ‹æ—¶ç¼–ç æ˜¯å¦ä¸€è‡´
3. âœ… å½’ä¸€åŒ–åçš„å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´
4. âœ… æ¨¡å‹æ€§èƒ½æ˜¯å¦æå‡

### æµ‹è¯•ä»£ç 

```python
# æ·»åŠ è°ƒè¯•æ—¥å¿—
def train(self, X_train, Y_train, categorical_features):
    logger.info(f"Categorical features input: {categorical_features}")
    logger.info(f"X_train columns: {X_train.columns.tolist()}")
    
    categorical_features = [f for f in categorical_features if f in X_train.columns]
    logger.info(f"Actual categorical features: {categorical_features}")
    
    # ... åç»­ä»£ç 
```

---

## ğŸ“ æ€»ç»“

### å½“å‰æœ€ä¸¥é‡çš„é—®é¢˜
1. **ç±»åˆ«ç‰¹å¾å¤„ç†å®Œå…¨å¤±æ•ˆ** - å¿…é¡»ç«‹å³ä¿®å¤
2. è®­ç»ƒå’Œé¢„æµ‹ç¼–ç ä¸ä¸€è‡´ - å¯èƒ½å¯¼è‡´é¢„æµ‹é”™è¯¯
3. ä»£ç é‡å¤ä¸¥é‡ - ç»´æŠ¤å›°éš¾

### æ¨èçš„ä¿®å¤ä¼˜å…ˆçº§
1. **P0ï¼ˆç«‹å³ï¼‰**: ä¿®å¤ç±»åˆ«ç‰¹å¾åˆå§‹åŒ–
2. **P1ï¼ˆæœ¬å‘¨ï¼‰**: ç»Ÿä¸€é¢„å¤„ç†é€»è¾‘
3. **P2ï¼ˆä¸‹å‘¨ï¼‰**: æ”¹ç”¨ StandardScaler å’Œ LightGBM åŸç”Ÿæ”¯æŒ
4. **P3ï¼ˆæœªæ¥ï¼‰**: ç‰¹å¾åˆ†ç»„å½’ä¸€åŒ–

### é¢„æœŸæ•ˆæœ
- âœ… ç±»åˆ«ç‰¹å¾è¢«æ­£ç¡®å¤„ç†
- âœ… æ¨¡å‹æ€§èƒ½æå‡ 5-15%
- âœ… ä»£ç æ›´ç®€æ´ã€å¯ç»´æŠ¤
- âœ… è®­ç»ƒå’Œé¢„æµ‹é€»è¾‘ä¸€è‡´
